project: retail360
environment: dev
platform: aws
spark:
  shuffle_partitions: 4
  extra_conf:
    spark.sql.files.maxPartitionBytes: 134217728
datasets:
  - name: products_bronze
    layer: bronze
    source:
      type: storage
      format: json
      uri: s3://landing/retail/products/
      infer_schema: true
      options:
        multiLine: true
    transform:
      add_ingestion_ts: true
      ops:
        - flatten_json:
            depth: 2
        - lowercase: [category]
        - trim: [product_name]
    validation:
      expect_not_null: [product_id, product_name]
      expect_set:
        col: status
        allowed: [active, discontinued]
    incremental:
      mode: append
      watermark_column: updated_at
    sink:
      type: storage
      format: parquet
      uri: s3://bronze/retail/products/
      options:
        mergeSchema: true
        compression: snappy
  - name: products_gold
    layer: gold
    source:
      type: storage
      format: parquet
      uri: s3://bronze/retail/products/
      options:
        mergeSchema: true
    transform:
      ops:
        - rename:
            product_name: name
            category: category_code
        - cast:
            price: decimal(12,2)
        - deduplicate:
            keys: [product_id]
            order_by: ["updated_at DESC", "_ingestion_ts DESC"]
    validation:
      expect_unique: [product_id]
      expect_between:
        col: price
        min: 0
        max: 9999
    incremental:
      mode: merge
      keys: [product_id]
      order_by: ["updated_at DESC", "_ingestion_ts DESC"]
    sink:
      type: warehouse
      engine: redshift
      table: analytics.products_gold
      options:
        batchsize: 5000
        truncate: false
        isolationLevel: SERIALIZABLE
        createTableOptions: "DISTSTYLE KEY DISTKEY(product_id) SORTKEY(updated_at)"
