#!/usr/bin/env python3
"""
Script simple para probar el pipeline de datos localmente usando pandas.
Este script simula el procesamiento que har√≠a Spark en un entorno de desarrollo.
"""

import pandas as pd
import yaml
import json
import os
from datetime import datetime
from pathlib import Path

def load_config(config_path):
    """Carga la configuraci√≥n del pipeline"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def process_payments_data(config):
    """Procesa los datos de pagos seg√∫n la configuraci√≥n"""
    print(f"üöÄ Iniciando pipeline: {config['id']}")
    
    # 1. Leer datos de origen
    source_path = config['source']['path']
    print(f"üìñ Leyendo datos desde: {source_path}")
    
    if not os.path.exists(source_path):
        raise FileNotFoundError(f"Archivo de datos no encontrado: {source_path}")
    
    df = pd.read_csv(source_path)
    print(f"‚úÖ Le√≠dos {len(df)} registros desde el origen")
    
    # 2. Mostrar muestra de datos originales
    print("\nüìä Muestra de datos originales:")
    print(df.head())
    print(f"\nColumnas: {list(df.columns)}")
    print(f"Tipos de datos:\n{df.dtypes}")
    
    # 3. Aplicar transformaciones
    print("\nüîÑ Aplicando transformaciones...")
    
    # Filtrar solo pagos completados
    df_filtered = df[df['status'] == 'completed'].copy()
    print(f"‚úÖ Filtrados {len(df_filtered)} pagos completados de {len(df)} totales")
    
    # Agregar fecha de procesamiento
    df_filtered['processing_date'] = datetime.now()
    
    # Calcular monto en USD
    def convert_to_usd(row):
        if row['currency'] == 'USD':
            return row['amount']
        elif row['currency'] == 'EUR':
            return row['amount'] * 1.1
        elif row['currency'] == 'GBP':
            return row['amount'] * 1.25
        else:
            return row['amount']
    
    df_filtered['amount_usd'] = df_filtered.apply(convert_to_usd, axis=1)
    
    # 4. Validaciones de calidad de datos
    print("\nüîç Ejecutando validaciones de calidad de datos...")
    
    # Verificar que los montos sean positivos
    negative_amounts = df_filtered[df_filtered['amount'] <= 0]
    if len(negative_amounts) > 0:
        print(f"‚ö†Ô∏è  ADVERTENCIA: {len(negative_amounts)} registros con montos negativos o cero")
    else:
        print("‚úÖ Todos los montos son positivos")
    
    # Verificar que payment_id no sea nulo
    null_payment_ids = df_filtered[df_filtered['payment_id'].isnull()]
    if len(null_payment_ids) > 0:
        print(f"‚ùå ERROR: {len(null_payment_ids)} registros con payment_id nulo")
    else:
        print("‚úÖ Todos los payment_id son v√°lidos")
    
    # Verificar monedas v√°lidas
    valid_currencies = ['USD', 'EUR', 'GBP']
    invalid_currencies = df_filtered[~df_filtered['currency'].isin(valid_currencies)]
    if len(invalid_currencies) > 0:
        print(f"‚ö†Ô∏è  ADVERTENCIA: {len(invalid_currencies)} registros con monedas no v√°lidas")
        print(f"Monedas encontradas: {df_filtered['currency'].unique()}")
    else:
        print("‚úÖ Todas las monedas son v√°lidas")
    
    # 5. Mostrar estad√≠sticas finales
    print("\nüìà Estad√≠sticas del procesamiento:")
    print(f"‚Ä¢ Registros procesados: {len(df_filtered)}")
    print(f"‚Ä¢ Pa√≠ses √∫nicos: {df_filtered['country'].nunique()}")
    print(f"‚Ä¢ Monedas √∫nicas: {df_filtered['currency'].nunique()}")
    print(f"‚Ä¢ Monto total (USD): ${df_filtered['amount_usd'].sum():,.2f}")
    print(f"‚Ä¢ Monto promedio (USD): ${df_filtered['amount_usd'].mean():.2f}")
    
    # 6. Guardar resultados
    output_path = config['destination']['path']
    os.makedirs(output_path, exist_ok=True)
    
    # Guardar como CSV para facilitar la inspecci√≥n
    output_file = os.path.join(output_path, 'processed_payments.csv')
    df_filtered.to_csv(output_file, index=False)
    print(f"\nüíæ Datos procesados guardados en: {output_file}")
    
    # Guardar tambi√©n como JSON para inspecci√≥n
    output_json = os.path.join(output_path, 'processed_payments.json')
    df_filtered.to_json(output_json, orient='records', date_format='iso', indent=2)
    print(f"üíæ Datos tambi√©n guardados en formato JSON: {output_json}")
    
    # 7. Generar reporte de m√©tricas
    metrics = {
        'pipeline_id': config['id'],
        'execution_time': datetime.now().isoformat(),
        'input_records': len(df),
        'output_records': len(df_filtered),
        'data_quality_score': 1.0 - (len(negative_amounts) + len(null_payment_ids)) / len(df_filtered) if len(df_filtered) > 0 else 0,
        'countries_processed': df_filtered['country'].nunique(),
        'currencies_processed': df_filtered['currency'].nunique(),
        'total_amount_usd': float(df_filtered['amount_usd'].sum()),
        'average_amount_usd': float(df_filtered['amount_usd'].mean())
    }
    
    metrics_file = os.path.join(output_path, 'pipeline_metrics.json')
    with open(metrics_file, 'w') as f:
        json.dump(metrics, f, indent=2)
    print(f"üìä M√©tricas guardadas en: {metrics_file}")
    
    print(f"\nüéâ Pipeline completado exitosamente!")
    return df_filtered, metrics

def main():
    """Funci√≥n principal"""
    config_path = "config/sample_pipeline.yml"
    
    try:
        # Cargar configuraci√≥n
        config = load_config(config_path)
        
        # Procesar datos
        processed_data, metrics = process_payments_data(config)
        
        print(f"\n‚ú® Resumen final:")
        print(f"‚Ä¢ Pipeline: {config['id']}")
        print(f"‚Ä¢ Registros procesados: {metrics['output_records']}")
        print(f"‚Ä¢ Calidad de datos: {metrics['data_quality_score']:.2%}")
        print(f"‚Ä¢ Monto total procesado: ${metrics['total_amount_usd']:,.2f} USD")
        
    except Exception as e:
        print(f"‚ùå Error en el pipeline: {e}")
        raise

if __name__ == "__main__":
    main()