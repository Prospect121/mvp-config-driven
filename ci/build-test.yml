name: Build & Test

on:
  push:
    branches:
      - feature/main-codex
  pull_request:
    branches:
      - feature/main-codex

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Enforce absence of legacy artifacts
        run: python tools/audit_cleanup.py --check

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install build

      - name: Build wheel
        run: python -m build

      - name: Upload wheel artifact
        uses: actions/upload-artifact@v4
        with:
          name: mvp-config-driven-${{ matrix.python-version }}-wheel
          path: dist/*.whl

      - name: Run tests with coverage
        env:
          PYTHONPATH: src
        run: pytest --cov=src/datacore --cov-report=term-missing

  smoke:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Run smoke suite placeholder
        env:
          PYTHONPATH: src
        run: |
          set -o pipefail
          echo "prodi plan/run sustituirÃ¡ al legacy smoke una vez disponible" | tee smoke.log

      - name: Upload smoke logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-logs
          path: smoke.log

  smoke-prod:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Validate production configs (forced dry-run)
        env:
          PYTHONPATH: src
        run: |
          set -o pipefail
          bash scripts/smoke_prod_configs.sh 2>&1 | tee smoke-prod.log

      - name: Upload production smoke logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-prod-logs
          path: smoke-prod.log

  validate-configs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Enforce configuration guardrails
        run: |
          set -euo pipefail
          python - <<'PY'
import sys
from collections import defaultdict
from collections.abc import Mapping
from pathlib import Path

import yaml

root = Path("cfg")
if not root.exists():
    sys.exit(0)

prod_paths = {path for path in root.rglob("*.prod.yml")}
duplicate_auth_headers: set[Path] = set()
missing_state_ids: set[Path] = set()
prod_missing_environment: set[Path] = set()
prod_authorization_headers: set[Path] = set()
hardcoded_auth_values: dict[Path, list[str]] = defaultdict(list)

ALLOWED_LITERAL_AUTH_VALUES = {
    "managed_identity",
    "workload_identity",
    "iam_role",
    "federated_identity",
    "service_principal",
}
ALLOWED_TYPE_LITERALS = {"bearer_env", "managed_identity", "oauth_service_principal"}


def iter_mappings(node):
    if isinstance(node, Mapping):
        yield node
        for value in node.values():
            yield from iter_mappings(value)
    elif isinstance(node, list):
        for item in node:
            yield from iter_mappings(item)


def safe_documents(path: Path):
    with path.open("r", encoding="utf-8") as handle:
        for raw in yaml.safe_load_all(handle):
            if isinstance(raw, Mapping):
                yield raw


def is_safe_auth_value(key: str, value) -> bool:
    if not isinstance(value, str):
        return True
    candidate = value.strip()
    if not candidate:
        return False
    if "{{" in candidate and "}}" in candidate:
        return True
    if candidate.isupper() and all(ch.isupper() or ch.isdigit() or ch == "_" for ch in candidate):
        return True
    if candidate in ALLOWED_LITERAL_AUTH_VALUES:
        return True
    if key == "type" and candidate in ALLOWED_TYPE_LITERALS:
        return True
    return False


for path in sorted(root.rglob("*.yml")):
    is_prod = path in prod_paths
    for document in safe_documents(path):
        if is_prod and document.get("environment") != "production":
            prod_missing_environment.add(path)

        for mapping in iter_mappings(document):
            if not isinstance(mapping, Mapping):
                continue

            headers = mapping.get("headers")
            auth = mapping.get("auth")
            incremental = mapping.get("incremental")

            if isinstance(auth, Mapping):
                if isinstance(headers, Mapping) and "Authorization" in headers:
                    duplicate_auth_headers.add(path)
                if is_prod:
                    for key, value in auth.items():
                        if not is_safe_auth_value(str(key), value):
                            hardcoded_auth_values[path].append(f"{key}={value}")

            if is_prod and isinstance(headers, Mapping) and "Authorization" in headers:
                prod_authorization_headers.add(path)

            if isinstance(incremental, Mapping):
                watermark = incremental.get("watermark")
                state_id = None
                if isinstance(watermark, Mapping):
                    state_id = watermark.get("state_id")
                if not isinstance(state_id, str) or not state_id.strip():
                    missing_state_ids.add(path)


def emit(title: str, paths):
    print(title, file=sys.stderr)
    for path in sorted(paths):
        print(f"  - {path}", file=sys.stderr)


has_errors = False

if duplicate_auth_headers:
    has_errors = True
    emit("[auth-lint] Found Authorization header alongside auth mapping:", duplicate_auth_headers)

if missing_state_ids:
    has_errors = True
    emit("[config] Incremental watermark requires state_id:", missing_state_ids)

if prod_missing_environment:
    has_errors = True
    emit("[config] Production configs must declare environment: production:", prod_missing_environment)

if prod_authorization_headers:
    has_errors = True
    emit("[config] Production configs must not embed headers.Authorization:", prod_authorization_headers)

if hardcoded_auth_values:
    has_errors = True
    print("[config] Production auth blocks must reference environment variables or managed identities:", file=sys.stderr)
    for path in sorted(hardcoded_auth_values):
        details = ", ".join(sorted(hardcoded_auth_values[path]))
        print(f"  - {path}: {details}", file=sys.stderr)

if has_errors:
    sys.exit(1)
PY

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install CLI dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Validate all configs
        run: |
          set -euo pipefail
          find cfg -type f -name "*.yml" -print0 | xargs -0 -I{} prodi validate -c "{}"

  smoke-finance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Run finance pipeline smoke (dry-run)
        env:
          PYTHONPATH: src
          PRODI_FORCE_DRY_RUN: "1"
        run: |
          set -euo pipefail
          : > smoke-finance.log
          echo "[smoke-finance] Running RAW_SOURCE=http" | tee -a smoke-finance.log
          PRODI_FORCE_DRY_RUN=1 prodi run-pipeline -p cfg/pipelines/finance_transactions.yml --vars RAW_SOURCE=http 2>&1 | tee -a smoke-finance.log
          echo "[smoke-finance] Running RAW_SOURCE=jdbc" | tee -a smoke-finance.log
          PRODI_FORCE_DRY_RUN=1 prodi run-pipeline -p cfg/pipelines/finance_transactions.yml --vars RAW_SOURCE=jdbc 2>&1 | tee -a smoke-finance.log

      - name: Upload finance smoke logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-finance-log
          path: smoke-finance.log
