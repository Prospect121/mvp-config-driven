id: payments_high_volume

source:
  input_format: csv
  path: "s3a://raw/casos-uso/payments-high-volume/*.csv"
  options:
    header: "true"
    inferSchema: "false"  # Control manual de tipos para mejor performance
    multiline: "true"
    escape: "\""
    quote: "\""
    timestampFormat: "yyyy-MM-dd HH:mm:ss"

standardization:
  timezone: America/Bogota
  
  rename:
    - { from: "Payment ID", to: payment_id }
    - { from: "Customer ID", to: customer_id }
    - { from: "Payment Amount", to: amount }
    - { from: "Payment Currency", to: currency }
    - { from: "Payment Date", to: payment_date }
    - { from: "Last Updated", to: updated_at }
    - { from: "Payment Method", to: payment_method }
    - { from: "Transaction Status", to: status }
    - { from: "Merchant ID", to: merchant_id }
    - { from: "Reference Number", to: reference_number_test }
  
  casts:
    - { column: amount, to: "decimal(18,2)", on_error: null }
    - { column: payment_date, to: "timestamp", format_hint: "yyyy-MM-dd[ HH:mm:ss]", on_error: null }
    - { column: updated_at, to: "timestamp", format_hint: "yyyy-MM-dd[ HH:mm:ss]", on_error: null }
    - { column: merchant_id, to: "integer", on_error: null }
  
  defaults:
    - { column: currency, value: "USD" }
    - { column: status, value: "PENDING" }
    - { column: reference_number_test, value: "" }
  
  deduplicate:
    key: [payment_id, customer_id]
    order_by: ["updated_at desc", "amount desc"]

quality:
  expectations_ref: config/datasets/casos_uso/payments_high_volume_expectations.yml
  quarantine: s3a://raw/quarantine/payments-high-volume/

schema:
  ref: config/datasets/casos_uso/payments_high_volume_schema.json
  mode: strict

output:
  silver:
    format: parquet
    path: "s3a://silver/payments-high-volume/"
    partition_by: [year, month]
    merge_schema: true
    mode: overwrite_dynamic
    partition_from: payment_date
    
    # Optimizaciones para alto volumen
    options:
      "spark.sql.adaptive.enabled": "true"
      "spark.sql.adaptive.coalescePartitions.enabled": "true"
      "spark.sql.adaptive.skewJoin.enabled": "true"

  gold:
    enabled: true
    database_config: "config/database.yml"
    environment: "development"
    
    exclude_columns: ["_run_id", "_ingestion_ts", "year", "month"]
    
    # add_columns:
    #   - { name: "data_source", value: "high_volume_payments", type: "string" }
    #   - { name: "processed_at", value: "current_timestamp()", type: "timestamp" }
    #   - { name: "batch_id", value: "uuid()", type: "string" }
    #   - { name: "pipeline_version", value: "v2.1.0", type: "string" }
    
    business_rules:
      - { condition: "amount > 0", action: "filter" }
      - { condition: "currency IS NOT NULL", action: "filter" }
      - { condition: "status IN ('COMPLETED', 'PENDING', 'FAILED', 'PROCESSING', 'CANCELLED', 'REFUNDED')", action: "filter" }
      - { condition: "payment_date >= '2020-01-01'", action: "filter" }
      - { condition: "merchant_id IS NOT NULL AND merchant_id > 0", action: "filter" }