# ---------- Azure base ----------
prefix                = "mvp"
location              = "centralus"
resource_group_name   = "rg-mvp-cu"
# Debe ser único globalmente, 3-24 chars, minúsculas y números
storage_account_name  = "stmvpconfigdls02"
subscription_id       = "<YOUR_SUBSCRIPTION_ID>"

# ---------- Configs locales ----------
# Directorio raíz local donde están los YAMLs a subir
local_config_root      = "../../config"
# Ruta relativa dentro del filesystem para el dataset.yml
# (se concatenará al contenedor 'configs')
dataset_config_path    = "datasets/finanzas/payments_v1/dataset.yml"

# ---------- Databricks cluster/job ----------
spark_version          = "14.3.x-scala2.12"
node_type_id           = "Standard_D4s_v3"
num_workers            = 0

# ---------- ADLS Gen2 OAuth (App Registration) ----------
# Reemplaza estos valores por los de tu App Registration con permisos sobre el Storage
# Preferiblemente carga el secreto desde variable de entorno o secret manager
tenant_id              = "<TENANT_ID>"
aad_client_id          = "<CLIENT_ID>"
aad_client_secret      = "<SECRET_FROM_ENV>"

# ---------- Wheel local ----------
# Si se omite, se calculará automáticamente a un wheel en dist/ (ver databricks.tf)
package_wheel_filename = "mvp_config_driven-0.1.1-py3-none-any.whl"
package_name           = "mvp_config_driven"
# local_wheel_path       = "dist/tu-wheel.whl"